{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"E7f_QYB9HwEt"},"source":["# Advanced Certification Programme in AI and MLOps\n","## A programme by IISc and TalentSprint\n","### Ungraded Additional Notebook: Decision Tree"]},{"cell_type":"markdown","metadata":{"id":"nbyDMbiY9Bhr"},"source":["## Learning Objective"]},{"cell_type":"markdown","metadata":{"id":"xfCEWqg09Ffu"},"source":["At the end of the experiment, you will be able :\n","\n","* Split the data into train and test sets\n","* Apply decision tree classifier with varying max_depth\n","* Visualize the decision tree\n","* Understand various performance metrics"]},{"cell_type":"markdown","source":["### Importing Libraries"],"metadata":{"id":"Hll_zPaZdvL4"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier, export_graphviz\n","from IPython.display import Image\n","import pydotplus"],"metadata":{"id":"i3LPn5m3eHLd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Download Iris Dataset"],"metadata":{"id":"48Wia6my4aTg"}},{"cell_type":"markdown","source":["<img src='https://drive.google.com/uc?id=1Z7BNkBDwojR2Ei3hoNMKnhGTowEULXei'>"],"metadata":{"id":"CS9nxYHAiBc1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TuCgdhwAdsRR","cellView":"form"},"outputs":[],"source":["#@title Download dataset\n","from IPython.display import clear_output\n","!wget https://cdn.iisc.talentsprint.com/AIandMLOps/Datasets/iris.csv\n","clear_output()\n","print(\"Dataset Downloaded!\")\n","!ls | grep \".csv\""]},{"cell_type":"code","source":["data = pd.read_csv('iris.csv')\n","data.head()"],"metadata":{"id":"zXn2q27_d9nv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Features\n","X = data.iloc[:, :4].values\n","\n","# Target\n","Y = data['Name'].values"],"metadata":{"id":"qi2CMc4zetm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y"],"metadata":{"id":"k_pWs2XOeyyh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Encoding the categorical label"],"metadata":{"id":"b62sBDzFf-m9"}},{"cell_type":"code","source":["# For example encoding target feature y\n","\n","enc = LabelEncoder()\n","label_encoder = enc.fit(Y)\n","y = label_encoder.transform(Y)\n","y"],"metadata":{"id":"s52pWKE4fVQy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Unique catogories in target column\n","enc.classes_"],"metadata":{"id":"gfzoYfY9pcbh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Again inversing the encoding\n","enc.inverse_transform(y)"],"metadata":{"id":"8sL3U0pXfrbS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Displaying the classes and their equivalent encoded values"],"metadata":{"id":"7XYB62dGgaxB"}},{"cell_type":"code","source":["print (\"Categorical classes:\", label_encoder.classes_)\n","\n","integer_classes = label_encoder.transform(label_encoder.classes_)\n","print (\"Integer classes:\", integer_classes)"],"metadata":{"id":"69rrwZdHfxgK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Training a  Classifier**\n","\n","* Iterating the depth ranging from 1 to 4\n","* Performing decision tree classifier with each depth displaying the graph"],"metadata":{"id":"JxmyazrAhFrO"}},{"cell_type":"markdown","source":["#### **Training and plotting the tree with Depth=1**"],"metadata":{"id":"aiOnkrP0s8od"}},{"cell_type":"code","source":["# Training and testing set ratio is 67 : 33\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n","\n","X_train.shape, X_test.shape, y_train.shape, y_test.shape"],"metadata":{"id":"CgqyvXlHoLzg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Training"],"metadata":{"id":"v2xXNIDdtYBV"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier(max_depth=1, criterion='entropy')\n","\n","# Fitting the data\n","clf.fit(X_train, y_train)"],"metadata":{"id":"o447SKvMq7EB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicting on test set\n","pred = clf.predict(X_test)\n","print(\"Prediction of test set : \\n\", pred)"],"metadata":{"id":"gC2DPmmQq-v9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Prediction of test set : \\n\", label_encoder.inverse_transform(pred))"],"metadata":{"id":"_Egvx4RorEhZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# accuracy on test set\n","print(\"\\nAccuracy score on test set : \", clf.score(X_test, y_test))"],"metadata":{"id":"VyKERpHnh42K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.columns.values"],"metadata":{"id":"nhjLM7FS-7MC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Plotting the tree"],"metadata":{"id":"GUk3SC6VnsIq"}},{"cell_type":"code","source":["feature_names = data.columns.values[:4]\n","target_names = np.array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n","\n","# Create DOT data\n","dot_data = export_graphviz(clf, out_file=None, feature_names=feature_names,  class_names=target_names)\n","\n","# Draw graph\n","graph = pydotplus.graph_from_dot_data(dot_data)\n","\n","# Show graph\n","Image(graph.create_png())"],"metadata":{"id":"FUnpdQABjtKx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Plotting Decision Boundary**"],"metadata":{"id":"3MUT6_TEtGcM"}},{"cell_type":"code","source":["# Consider only 2 feature, so that they can be visualize in a 2D plot\n","reduced_features = X_train[:, [2,3]]          # petal length,  petal width"],"metadata":{"id":"GZMWvSpgc4NJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot data points\n","\n","sns.scatterplot(x=reduced_features[:, 0], y=reduced_features[:, 1], hue = label_encoder.inverse_transform(y_train))\n","plt.xlabel('Petal length (cm)')\n","plt.ylabel('Petal width (cm)')\n","plt.show()"],"metadata":{"id":"py2RJWPncZoN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train model using only 2 features\n","clf = DecisionTreeClassifier(max_depth=1, criterion='entropy')\n","\n","# Fitting the data\n","clf.fit(reduced_features, y_train)"],"metadata":{"id":"yTSPrl2_a3S8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a meshgrid of points to plot\n","x_min, x_max = reduced_features[:, 0].min() - 1, reduced_features[:, 0].max() + 1\n","y_min, y_max = reduced_features[:, 1].min() - 1, reduced_features[:, 1].max() + 1\n","xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n","\n","# Plot the decision boundary\n","Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n","Z = Z.reshape(xx.shape)\n","plt.contourf(xx, yy, Z, alpha=0.6)\n","\n","# Plot the training data\n","sns.scatterplot(x=reduced_features[:,0], y=reduced_features[:,1], hue = label_encoder.inverse_transform(y_train))\n","\n","# Set the title and labels\n","plt.title('Decision Boundary of Decision Tree (Depth=1)')\n","plt.xlabel('Reduced Feature 1')\n","plt.ylabel('Reduced Feature 2')\n","plt.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"tZ8gNetSa_Dy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Training and plotting the tree with Depth=2**"],"metadata":{"id":"qMYrtKI8tMNC"}},{"cell_type":"markdown","source":["##### Training"],"metadata":{"id":"sqvP1blNtgq6"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier(max_depth=2, criterion='entropy', min_samples_split=2)\n","\n","# Fitting the data\n","clf.fit(X_train,y_train)\n","\n","# Predicting on test set\n","pred = clf.predict(X_test)\n","print(\"Prediction of test set : \\n\", label_encoder.inverse_transform(pred))\n","\n","# accuracy on test set\n","print(\"\\nAccuracy score on test set : \", clf.score(X_test, y_test))"],"metadata":{"id":"Im6niE7KtNui"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Plotting the tree"],"metadata":{"id":"IDC05D28te_4"}},{"cell_type":"code","source":["feature_names = data.columns.values[:4]\n","target_names = np.array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n","\n","# Create DOT data\n","dot_data = export_graphviz(clf, out_file=None, feature_names=feature_names,  class_names=target_names)\n","\n","# Draw graph\n","graph = pydotplus.graph_from_dot_data(dot_data)\n","\n","# Show graph\n","Image(graph.create_png())"],"metadata":{"id":"tRbUrPk7tlZa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Plotting Decision Boundary**"],"metadata":{"id":"_Yp2t_ACy0lF"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier(max_depth=2, criterion='entropy', min_samples_split=2)\n","\n","# Fitting the data\n","clf.fit(reduced_features, y_train)"],"metadata":{"id":"MpbphliJbRNN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a meshgrid of points to plot\n","x_min, x_max = reduced_features[:, 0].min() - 1, reduced_features[:, 0].max() + 1\n","y_min, y_max = reduced_features[:, 1].min() - 1, reduced_features[:, 1].max() + 1\n","xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n","\n","# Plot the decision boundary\n","Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n","Z = Z.reshape(xx.shape)\n","plt.contourf(xx, yy, Z, alpha=0.6)\n","\n","# Plot the training data\n","sns.scatterplot(x=reduced_features[:,0], y=reduced_features[:,1], hue = label_encoder.inverse_transform(y_train))\n","\n","# Set the title and labels\n","plt.title('Decision Boundary of Decision Tree (Depth=2)')\n","plt.xlabel('Reduced Feature 1')\n","plt.ylabel('Reduced Feature 2')\n","plt.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"IALEMM4ybagQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Training and plotting the tree with Depth=3**"],"metadata":{"id":"_j4I3tgqt9ou"}},{"cell_type":"markdown","source":["##### Training"],"metadata":{"id":"OUXdtWtHt9ow"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier(max_depth=3, criterion='entropy')\n","\n","# Fitting the data\n","clf.fit(X_train,y_train)\n","\n","# Predicting on test set\n","pred = clf.predict(X_test)\n","print(\"Prediction of test set : \\n\", label_encoder.inverse_transform(pred))\n","\n","# Accuracy on test set\n","print(\"\\nAccuracy score on test set : \", clf.score(X_test, y_test))"],"metadata":{"id":"cbRfEIU-t9oy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Plotting the tree"],"metadata":{"id":"dei89N5ht9o5"}},{"cell_type":"code","source":["feature_names = data.columns.values[:4]\n","target_names = np.array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n","\n","# Create DOT data\n","dot_data = export_graphviz(clf, out_file=None, feature_names=feature_names,  class_names=target_names)\n","\n","# Draw graph\n","graph = pydotplus.graph_from_dot_data(dot_data)\n","\n","# Show graph\n","Image(graph.create_png())"],"metadata":{"id":"ljHa6SYWt9o8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Plotting Decision Boundary**"],"metadata":{"id":"HZnq2WTlzGAx"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier(max_depth=3, criterion='entropy')\n","\n","# Fitting the data\n","clf.fit(reduced_features, y_train)"],"metadata":{"id":"Cx-agbMIboEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a meshgrid of points to plot\n","x_min, x_max = reduced_features[:, 0].min() - 1, reduced_features[:, 0].max() + 1\n","y_min, y_max = reduced_features[:, 1].min() - 1, reduced_features[:, 1].max() + 1\n","xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n","\n","# Plot the decision boundary\n","Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n","Z = Z.reshape(xx.shape)\n","plt.contourf(xx, yy, Z, alpha=0.6)\n","\n","# Plot the training data\n","sns.scatterplot(x=reduced_features[:,0], y=reduced_features[:,1], hue = label_encoder.inverse_transform(y_train))\n","\n","# Set the title and labels\n","plt.title('Decision Boundary of Decision Tree (Depth=3)')\n","plt.xlabel('Reduced Feature 1')\n","plt.ylabel('Reduced Feature 2')\n","plt.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"PMHgrWHTbr5K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **Training and plotting the tree with Depth=5**"],"metadata":{"id":"ZiVmWf3juVmv"}},{"cell_type":"markdown","source":["##### Training"],"metadata":{"id":"heHLE4dpuVmy"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier(max_depth=5, criterion='entropy')\n","\n","# Fitting the data\n","clf.fit(X_train,y_train)\n","\n","# Predicting on test set\n","y_pred = clf.predict(X_test)\n","print(\"prediction of test set : \\n\", label_encoder.inverse_transform(y_pred))\n","\n","# Accuracy on test set\n","print(\"\\nAccuracy score on test set : \", clf.score(X_test, y_test))"],"metadata":{"id":"O29pCKGIuVm1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Plotting the tree"],"metadata":{"id":"pt6b429puVm4"}},{"cell_type":"code","source":["feature_names = data.columns.values[:4]\n","target_names = np.array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\n","\n","# Create DOT data\n","dot_data = export_graphviz(clf, out_file=None, feature_names=feature_names,  class_names=target_names)\n","\n","# Draw graph\n","graph = pydotplus.graph_from_dot_data(dot_data)\n","\n","# Show graph\n","Image(graph.create_png())"],"metadata":{"id":"zqUEWSgcuVm6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Plotting Decision Boundary"],"metadata":{"id":"wlm_1pIhzHHR"}},{"cell_type":"code","source":["clf = DecisionTreeClassifier(max_depth=5, criterion='entropy')\n","\n","# Fitting the data\n","clf.fit(reduced_features, y_train)"],"metadata":{"id":"2P_ms5jab-6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a meshgrid of points to plot\n","x_min, x_max = reduced_features[:, 0].min() - 1, reduced_features[:, 0].max() + 1\n","y_min, y_max = reduced_features[:, 1].min() - 1, reduced_features[:, 1].max() + 1\n","xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n","\n","# Plot the decision boundary\n","Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n","Z = Z.reshape(xx.shape)\n","plt.contourf(xx, yy, Z, alpha=0.6)\n","\n","# Plot the training data\n","sns.scatterplot(x=reduced_features[:,0], y=reduced_features[:,1], hue = label_encoder.inverse_transform(y_train))\n","\n","# Set the title and labels\n","plt.title('Decision Boundary of Decision Tree (Depth=5)')\n","plt.xlabel('Reduced Feature 1')\n","plt.ylabel('Reduced Feature 2')\n","plt.legend()\n","\n","# Show the plot\n","plt.show()"],"metadata":{"id":"aiWEOcJ5cCUX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Confusion Matrix**"],"metadata":{"id":"DWuqgJXY5q3d"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix"],"metadata":{"id":"re3W6BV04zvg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('iris.csv')\n","df.head()"],"metadata":{"id":"yRnRP54U-4Te"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Condition expression to check whether the sample is of class 'Iris-setosa' or not\n","df['Name'] != 'Iris-setosa'"],"metadata":{"id":"7BDHajI9_mEL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Filter dataset to consider samples of class other than 'Iris-setosa'\n","df_b = df.loc[ df['Name'] != 'Iris-setosa']\n","df_b.shape"],"metadata":{"id":"Gubj9lYmGNYd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Features\n","X_b = df_b.iloc[:, :4].values\n","\n","# Target\n","Y_b = df_b['Name'].values"],"metadata":{"id":"XwT5dbhyG9x5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training and testing set ratio is 67 : 33\n","X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X_b, Y_b, test_size=0.3, random_state=42)"],"metadata":{"id":"YXwt7f6yHRza"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clf = DecisionTreeClassifier(max_depth=1, criterion='entropy')\n","\n","# Fitting the data\n","clf.fit(X_train_b,y_train_b)\n","\n","# Predicting on test set\n","y_pred_b = clf.predict(X_test_b)\n","\n","# Accuracy on test set\n","print(\"Accuracy score on test set : \", clf.score(X_test_b, y_test_b))"],"metadata":{"id":"NASqau3Q5liV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion matrix\n","mat = confusion_matrix(y_test_b, y_pred_b)\n","mat"],"metadata":{"id":"QdrNUKJv7znj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","target_names = np.array(['Iris-versicolor', 'Iris-virginica'])\n","sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels=target_names, yticklabels=target_names)\n","plt.xlabel('True Labels')\n","plt.ylabel('Predicted Labels')\n","plt.show()"],"metadata":{"id":"ZOE2q17j8BrL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JnKMEUwPiER0"},"source":["#### Precision-Recall Metrics"]},{"cell_type":"markdown","source":["<img src='https://drive.google.com/uc?id=1pEQdkP-trVknuCImQbN3-XziyTPRYQIC' width=400px>"],"metadata":{"id":"GLIPFngwha_N"}},{"cell_type":"markdown","metadata":{"id":"AZ_xgAFUiEeq"},"source":["* **Precision:** The precision is calculated as the ratio between the number of Positive samples correctly classified to the total number of samples classified as Positive (either correctly or incorrectly)\n","\n","    Precision = $\\mathbf{\\frac{TruePositive}{TruePositive + FalsePositive}}$\n","\n","* **Recall:** Recall tells us how many true positives (points labelled as positive) were recalled or found by our model.\n","\n","   Recall = $\\mathbf{\\frac{TruePositive}{TruePositive + FalseNegative}}$\n","\n","* **F1-score:** precision and recall can be combined into a single score that seeks to balance both concerns, called the F-score or the F-measure.\n","  \n","   F1-score = $\\mathbf{\\frac{2*Precision*Recall}{Precision+Recall}}$"]},{"cell_type":"markdown","metadata":{"id":"fV0iHWlKbU5l"},"source":["#### Precision"]},{"cell_type":"code","metadata":{"id":"btDWhBYCDsf2"},"source":["from sklearn.metrics import precision_score\n","\n","precision_score(y_test_b, y_pred_b, average=\"macro\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sHksJdbxXkv9"},"source":["#### Recall"]},{"cell_type":"code","metadata":{"id":"gdMPEZlgXmUd"},"source":["from sklearn.metrics import recall_score\n","recall_score(y_test_b, y_pred_b, average=\"macro\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"egDuWesgQxRw"},"source":["####F1-score"]},{"cell_type":"code","metadata":{"id":"NMbjkrFd8fpj"},"source":["from sklearn.metrics import f1_score\n","f1_score(y_test_b, y_pred_b, average=\"macro\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ROC-AUC Score and Curve"],"metadata":{"id":"EGcTLMMsNuyj"}},{"cell_type":"markdown","source":["<center><img src='https://drive.google.com/uc?id=1_4LKC-FKTq1zdxsdZIS5eJnqR9KGbafb' width=400px></center>"],"metadata":{"id":"8BPZG6RNgrPV"}},{"cell_type":"code","source":["from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score"],"metadata":{"id":"YO9DZ5kTN7OS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mapper(x):\n","    maps = {\"Iris-virginica\": 0,\n","            \"Iris-versicolor\": 1}\n","    return maps[x]"],"metadata":{"id":"ksHW2IUnTRRE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test_b2 = [i for i in map(mapper, y_test_b)]\n","y_pred_b2 = [i for i in map(mapper, y_pred_b)]"],"metadata":{"id":"BZdzSetRTOuX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# False Positive Rate and True Positive Rate\n","fpr, tpr, _ = roc_curve(y_test_b2, y_pred_b2)\n","fpr, tpr"],"metadata":{"id":"gEhhQJj1OHHm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot([0,1], [0,1], linestyle='--', label='Untrained model', color='k')\n","plt.plot(fpr, tpr, marker='.', label='Trained DecisionTree')\n","plt.title('ROC Curve')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"KnJAcgmRT-PC"},"execution_count":null,"outputs":[]}]}